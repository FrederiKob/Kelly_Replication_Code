{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1d5e7A8i6vbxXk2yvx9hHYWthVexqN0Xl",
      "authorship_tag": "ABX9TyPMNhdzESqUQd7dyBwIpTA5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrederiKob/Kelly_Replication_Code/blob/main/Rudimentary_Replication_Kelly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section (1):**\n",
        "*   Pull Goyal & Welch Data from GitHub (2022 Data); Source: https://docs.google.com/spreadsheets/d/1g4LOaRj4TvwJr9RIaA_nwrXXWTOy46bP/edit?usp=share_link&ouid=113571510202500088860&rtpof=true&sd=true\n",
        "*   Create Variables needed for replication\n",
        "*   Volatility Standardize Predictors and Returns\n"
      ],
      "metadata": {
        "id": "ArE86AGlq5II"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W2FOBGufHaP",
        "outputId": "dc9b43aa-37ce-4a28-96ad-fbcb4dc965b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
            "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
          ]
        }
      ],
      "source": [
        "### Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "### Download from github\n",
        "url = \"https://github.com/FrederiKob/Kelly_Replication_Code/blob/91e1ba566e5b4c830061f4dc6ba1839a56c5dc0f/Data_Goyal_Welch_2022.xlsx?raw=True\"\n",
        "data = pd.read_excel(url, sheet_name=\"Monthly\", index_col=\"yyyymm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Offset the data since the data are month-end values"
      ],
      "metadata": {
        "id": "2pdcTRYHieWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.index = pd.to_datetime(data.index, format = \"%Y%m\") + pd.DateOffset(months = 1)"
      ],
      "metadata": {
        "id": "k1eStnEZilYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and Select required variables"
      ],
      "metadata": {
        "id": "Z972N7K_gsIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i) dfy -- Default Yield Spread (dfy) is the difference between BAA and AAA-rated corporate bond yields\n",
        "data[\"dfy\"] = data[\"BAA\"] - data[\"AAA\"]\n",
        "# ii) de -- The Dividend Payout Ratio (d/e) is the difference between the log of dividends and the log of earnings\n",
        "data[\"de\"] = np.log(data[\"D12\"]/data[\"E12\"])\n",
        "# iii) tms -- the term spread (tms) is the difference between the long term yield on government bonds and the Treasury-bill\n",
        "data[\"tms\"] = data[\"lty\"] - data[\"tbl\"]\n",
        "# iv) dfr -- Default Return Spread (dfr) is the difference between long-term corporate bond and long-term government bond returns\n",
        "data[\"dfr\"] = data.corpr - data.ltr\n",
        "# v) dp -- The Dividend Price Ratio (d/p) is the difference between the log of dividends and the log of prices\n",
        "data[\"dp\"] = np.log(data[\"D12\"]/data[\"Index\"])\n",
        "# vi) dy -- The Dividend Yield (d/y) is the difference between the log of dividends and the log of lagged prices\n",
        "data[\"dy\"] = np.log(data.D12/data.Index.shift(1))\n",
        "# vii) ep -- Earnings Price Ratio (e/p) is the difference between the log of earnings and the log of prices\n",
        "data[\"ep\"] = np.log(data.E12/data.Index)\n",
        "# Excess Returns (xr)\n",
        "data[\"xr\"] = data.CRSP_SPvw - data.Rfree\n",
        "# One lag of market returns\n",
        "data[\"lag_1\"] = data.CRSP_SPvw\n",
        "\n",
        "# Reduce to relevant variables\n",
        "data = data.loc[:, ['b/m', 'tbl', 'lty', 'ntis', 'infl', 'ltr', 'svar', 'dfy',\n",
        "                           'de', 'tms', 'dfr', 'dp', 'dy', 'ep', 'xr']].dropna()\n"
      ],
      "metadata": {
        "id": "iHLGTFr5gznp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volatility Standardize predictors and Returns\n",
        "\n",
        "a) Predictors: standardized using an expanding window historical standard deviation (at least 36 months for predictors)\n",
        "     apply to training and test predictors\n",
        "\n",
        "b) Returns: standardized by their trailing 12-month return standard deviation (this includes target and lagged market return)"
      ],
      "metadata": {
        "id": "Pl2XVFeCjEP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate Dataframes into predictors and returns (target)\n",
        "pred = data.copy().drop(\"xr\",axis=1)\n",
        "ret = pd.DataFrame(data.copy().xr)\n",
        "\n",
        "# (i) returns\n",
        "ret[\"roll_std\"] = ret.rolling(12).std(ddof=0) # rolling standard deviation\n",
        "ret[\"xr_std\"] = ret.xr/ret.roll_std.shift(1) # standardize xr(t) by std(t-1)\n",
        "ret[\"target\"] = ret.xr_std.shift(-1) # pull forward xr so that predictors and target assigned same date\n",
        "ret[\"lag_1\"] = ret.target.shift(1)\n",
        "ret_std = ret.drop([\"xr_std\",\"roll_std\",\"xr\"], axis=1)\n",
        "\n",
        "# (ii) predictors\n",
        "p_std = pred.copy().expanding(36).std(ddof=0)\n",
        "\"\"\" See Complexity Everywhere --> use up to t-1 std() to standardize t // WHY NOT USE t AS WELL ???\"\"\"\n",
        "pred_std = pred/p_std.shift(1)\n",
        "\n",
        "# (iii) combine predictors and isolate target (y)\n",
        "pred_std = pd.concat([pred_std, ret_std], axis=1).dropna()\n",
        "ret_std = pred_std.copy().target\n",
        "pred_std = pred_std.drop(\"target\",axis=1)\n",
        "del(p_std,pred,ret)\n"
      ],
      "metadata": {
        "id": "MjVxee0IjKtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TOVfcHAjkxWb"
      }
    }
  ]
}