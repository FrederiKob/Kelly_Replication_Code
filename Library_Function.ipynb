{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd7+jzJETWQSxdCsYJfaH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrederiKob/Kelly_Replication_Code/blob/main/Library_Function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "r5TvyPuNXbMb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Function Script includes the following functions:**\n",
        "\n",
        "\n",
        "1.   Generate w_i --> generates random N(0,1) draws used in the RFFs (*generate_w_i*)\n",
        "2.   Generate Signals --> generates RFF's for a specific seed and for a specific number of P's (*generate_Signals*)\n",
        "3.   Generate X and y samples used for fitting and predicting (*generate_X_y*)\n",
        "4.   Run predictions over all t's and over multiple iterations (*run_all*)"
      ],
      "metadata": {
        "id": "BMVsFys8t-zU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Generate w_i:\n",
        "Takes as input:\n",
        "*   max_iterations: number of iterations to average predictions over\n",
        "*   max_P: maximum nuber of P's used to generate RFF's (only need half since we are using cos and sin)\n",
        "*   will always be run using seeds from range(0, max_iterations) --> replicability guaranteed\n",
        "\n",
        "From Kelly et al. (2022) *The Virtue Complexity Everywhere* page 21:\n",
        "\"[...] given the signal vector $X_{t} = \\mathbb{R}^{d}$ [...] fix a random seed $s$ and sample random weights $w_{i}(s) \\in \\mathbb{R}^{d}$ from $\\mathcal{N} \\sim (0,I_{dxd})$ \"\n",
        "\n",
        "Hence, the w_i gets drawn from multivariate_normal mean = 0; covariance matrix = Identity.\n",
        "Resulting in a dictionary with max_iteration number of keys (name  with every key containing a matrix of shape max_P/2 x number of predictors (G = 15).\n",
        "\n",
        "=> every matrix is generated by the specific seed of range(max_iterations), thus the random draws and predicitons are easily replicated and can be used for all P-T-alpha generations.\n",
        ""
      ],
      "metadata": {
        "id": "Jpxe2kBZMf6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_w_i(max_iterations = None, max_P = None):\n",
        "    dic_wi = dict.fromkeys(range(max_iterations))\n",
        "    \"\"\" Always set seed to 0 --> generate max_iteration verisons of random draws used\n",
        "        --> one set of these random w_i's is used for one iteration\n",
        "    \"\"\"\n",
        "    for ite in range(max_iterations):\n",
        "        np.random.seed(ite)\n",
        "        # round so that sufficient w_i are drawn in case max_P is odd\n",
        "        w_i = np.random.multivariate_normal(mean = np.array([0]*15), cov = np.identity(15), size = int(round(max_P/2)))\n",
        "        dic_wi[ite] = w_i\n",
        "    return dic_wi"
      ],
      "metadata": {
        "id": "g64fzhoAMdYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. generate_signals:\n",
        "*   pred_std: standardized predictor variables used to generate signals (lagged market return is included)\n",
        "*   P: number of predictors to generate $P \\in [2,...,12000]$\n",
        "\n",
        "The signals or RFFs are generated as follows (see Kelly et al. (2022)):\n",
        " $S_{i,t}(s) = \\frac{1}{P^{1/2}}\\left [ sin(\\gamma w_{i}(s)'X_{t}), cos(\\gamma w_{i}(s)' X_{t}) \\right ]', i = 1,\\cdots, P$,\n",
        "\n",
        " where \"[...] the parameter $\\gamma$ controls the Gaussian kernel bandwitdth in the generation of random Fourier features [...] we set $\\gamma = 2$. Our results are generally insensitive to $\\gamma$...\" (page 39-40)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2yQtMvPgMy-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_Signals(pred_std = None, P = None, use_seed = None, w_i_all = None):\n",
        "    # gamma = 2\n",
        "    gamma = 2\n",
        "    # due to large number of iterations, assumed that ordering should be negligible ???\n",
        "    w_i = w_i_all[use_seed][:int(round(P/2))]\n",
        "    inside = gamma * w_i @ pred_std.T\n",
        "    # using trig-function\n",
        "    sig = (P**(-0.5) * np.cos(inside.T), P**(-0.5) * np.sin(inside.T))\n",
        "    signals = np.concatenate([sig[0], sig[1]], axis=1)\n",
        "    # check if even or odd\n",
        "    if P % 2 != 0:\n",
        "        # random item to drop --> due to one signal too many\n",
        "        drop = np.random.randint(0, P+1)\n",
        "        # drop random element --> correct size of signals\n",
        "        signals = np.matrix([np.delete(i, drop, 0) for i in signals])\n",
        "    else:\n",
        "        signals = np.matrix(signals)\n",
        "\n",
        "    # return signals\n",
        "    return signals\n"
      ],
      "metadata": {
        "id": "eg9lrzR1M7NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Generate X_y -->"
      ],
      "metadata": {
        "id": "frx0joEoM_VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Option_generate_X_y(signals = None, ret_std = None, idx_start = None, T = None, P = None, vol_stand = True):\n",
        "    \"\"\"\n",
        "    Prior to estimation, we volatility standardize the training sample RFFs {S_{t-1}, ..., S_{t-T}}\n",
        "    and out-of-sample RFFs S_{t} by their standard deviations in the training sample\n",
        "        --> XR remains untouched\n",
        "    \"\"\"\n",
        "    # pull T+1 observations --> T observations for train sample and idx_start is the target which we want to forecast\n",
        "    X = signals[idx_start-T:idx_start+1]\n",
        "    Y = ret_std[idx_start-T:idx_start+1]\n",
        "\n",
        "    X_train = X[:-1,:]\n",
        "    y_train = Y[:-1]\n",
        "\n",
        "    X_test = X[-1,:].reshape(1,-1)\n",
        "    y_test = Y[-1]\n",
        "\n",
        "    if vol_stand:\n",
        "        std = X_train.std(ddof=0, axis=0)\n",
        "        X_train = X_train/std\n",
        "        X_test = X_test/std\n",
        "        return (X_train,X_test),(y_train,y_test)\n",
        "    else:\n",
        "        return (X_train,X_test),(y_train,y_test)"
      ],
      "metadata": {
        "id": "cnuEX10aNEGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. run_all -->"
      ],
      "metadata": {
        "id": "J7TepIoCNJtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all(ret_std = None, pred_std = None, w_i_all = None, params = None, operations = None, end = None):\n",
        "    from sklearn.linear_model import Ridge\n",
        "    # combinations to run (taken from operations)\n",
        "    combs = operations[1]\n",
        "    # seeds and iterations needed\n",
        "    seed_start, iters_needed = operations[0]\n",
        "    # append results to\n",
        "    dic_res = {i:[] for i in combs}\n",
        "    dic_coef = {i:[] for i in combs}\n",
        "    # at what index to stop\n",
        "    idx_end = np.where(ret_std.index == end)[0][0]\n",
        "    # define counter\n",
        "    counter = seed_start\n",
        "    counter_stop = seed_start + iters_needed\n",
        "\n",
        "    # Start outer loop (over iterations)\n",
        "    while counter < counter_stop:\n",
        "        print(\"The current counter is: {} out of {} iterations\".format(counter,counter_stop))\n",
        "\n",
        "        # Start second loop over the combinations\n",
        "        for c in combs:\n",
        "          # parameters\n",
        "          T,P,alpha = c\n",
        "          # generate P-specific signals (used for all P)\n",
        "          signals = generate_Signals(pred_std=pred_std, P=P, use_seed=counter, w_i_all=w_i_all)\n",
        "          # lst to append predictions to\n",
        "          lst_res,lst_coef = [],[]\n",
        "\n",
        "          # Start third loop over all observations in T\n",
        "          for t in range(T,idx_end+1): # CHECK IF THIS CORRECT\n",
        "              # generate XY\n",
        "              x,y = generate_X_y(signals=signals,ret_std=ret_std, idx_start=t, T=T, P=P)\n",
        "              # fit and predict\n",
        "              clf = Ridge(alpha=alpha, fit_intercept=False)\n",
        "              clf.fit(X=x[0],y=y[0])\n",
        "              lst_res.append(clf.predict(x[1])[0])\n",
        "              lst_coef.append(sum(clf.coef_**2))\n",
        "\n",
        "          ## write to dictionary\n",
        "          dic_res[c].append(lst_res)\n",
        "          dic_coef[c].append(lst_coef)\n",
        "        # update\n",
        "        counter += 1\n",
        "\n",
        "    # write new or concatenate dataframes (results)\n",
        "    for c in combs:\n",
        "        dic_res[c] = pd.DataFrame(dic_res[c], columns=ret_std.index[c[0]:idx_end+1], index=range(seed_start,counter_stop)).T\n",
        "        dic_coef[c] = pd.DataFrame(dic_coef[c], columns=ret_std.index[c[0]:idx_end+1], index=range(seed_start,counter_stop)).T\n",
        "\n",
        "    return dic_res,dic_coef"
      ],
      "metadata": {
        "id": "k3zTCc50R9Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Plot Figure 10"
      ],
      "metadata": {
        "id": "XLpa2RRjSC3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_fig10(results = None, T = None, P = None, alpha = None, roll_window = None, begin = None, end = None):\n",
        "    ## Determine start and end of recession periods\n",
        "    from itertools import groupby\n",
        "    from operator import itemgetter\n",
        "\n",
        "    # pull recession data from FRED as dummy variables for a given month\n",
        "    nber = web.DataReader([\"USREC\"], \"fred\", start = begin, end = end)\n",
        "    _sth = np.where(nber.USREC == 1)[0]\n",
        "    rec = []\n",
        "    for k,g in groupby(enumerate(_sth), lambda ix: ix[0] - ix[1]):\n",
        "        rec.append(list(map(itemgetter(1),g)))\n",
        "    rec = [(nber.index[i[0]], nber.index[i[-1]]) for i in rec]\n",
        "    rec_b = [i[0] for i in rec]\n",
        "    rec_e = [i[1] for i in rec]\n",
        "\n",
        "    #fig, ax = plt.subplots()\n",
        "    # relevant combinations\n",
        "    plt.figure(dpi=2000)\n",
        "    lbl = []\n",
        "    cmbs = list(itertools.product(T,[P],[alpha]))\n",
        "    for n,c in enumerate(cmbs):\n",
        "        use = results[c].rolling(roll_window).mean().mean(axis=1).dropna()\n",
        "        use = use.loc[begin:end]\n",
        "        # plot\n",
        "        plt.plot(use, lw = 0.65, alpha = 0.8)\n",
        "        lbl.append(\"$\\hat{\\pi},T =$\" + str(int(c[0])))\n",
        "        rec_patches = [plt.axvspan(x1, x2, alpha=0.4, color='grey', zorder=2) for x1, x2 in zip(rec_b, rec_e)]\n",
        "        #rec_handle = Line2D([0], [0], color='orange', alpha=0.4, lw=4, label='NBER Recession')\n",
        "\n",
        "    #plt.legend(handles= [rec_handle])\n",
        "    lbl.append(\"NBER Recession\")\n",
        "    plt.legend(lbl)\n",
        "    plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "yUdG6frfSH7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}